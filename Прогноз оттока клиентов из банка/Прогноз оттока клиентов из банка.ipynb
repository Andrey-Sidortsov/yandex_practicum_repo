{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для README "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прогноз оттока клиентов из банка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Описание работы :\n",
    "\n",
    "Из банка стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.\n",
    "\n",
    "На основании исторических данных нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет.  \n",
    "\n",
    "Необходимо постройть модель со значением *F1*-меры не меньше 0.59, дополнительно измеряя метрику *AUC-ROC*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Описание данных :\n",
    "\n",
    "* `RowNumber` — индекс строки в данных\n",
    "* `CustomerId` — уникальный идентификатор клиента\n",
    "* `Surname` — фамилия\n",
    "* `CreditScore` — кредитный рейтинг\n",
    "* `Geography` — страна проживания\n",
    "* `Gender` — пол\n",
    "* `Age` — возраст\n",
    "* `Tenure` — количество недвижимости у клиента\n",
    "* `Balance` — баланс на счёте\n",
    "* `NumOfProducts` — количество продуктов банка, используемых клиентом\n",
    "* `HasCrCard` — наличие кредитной карты\n",
    "* `IsActiveMember` — активность клиента\n",
    "* `EstimatedSalary` — предполагаемая зарплата\n",
    "* `Exited` — факт ухода клиента"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "План работы над проектом :\n",
    "\n",
    "   1. [Подготовка данных:](#Step_1)\n",
    "       * [Обзор и загрузка данных](#Step_1_1)\n",
    "       * [Приведение названий столбцов к нижнему регистру](#Step_1_2)\n",
    "       * [Обработка пропусков](#Step_1_3)\n",
    "       * [Преобразование данных в нужные типы](#Step_1_4)\n",
    "       * [Обработка дубликатов](#Step_1_5)\n",
    "       * [Вывод](#Step_1_6)\n",
    "   2. [Исследование задачи](#Step_2)\n",
    "       * [Исследование баланса классов](#Step_2_1)\n",
    "       * [Изучение модели без учёта дисбаланса](#Step_2_2)\n",
    "       * [Вывод](#Step_2_3)\n",
    "   3. [Борьба с дисбалансом](#Step_3)\n",
    "       * [Исследование баланса классов](#Step_3_1)\n",
    "       * [Вывод](#Step_3_2)\n",
    "   4. [Тестирование модели](#Step_4)\n",
    "   5. [Общий вывод](#Step_5)\n",
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используемые библиотеки:\n",
    "\n",
    "- pandas \n",
    "- numpy\n",
    "- sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используемые инструменты:\n",
    "\n",
    "- from sklearn.model_selection import train_test_split\n",
    "- from sklearn.tree import DecisionTreeClassifier\n",
    "- from sklearn.metrics import accuracy_score\n",
    "- from sklearn.metrics import f1_score\n",
    "- from sklearn.metrics import roc_auc_score\n",
    "- from sklearn.utils import shuffle\n",
    "- from sklearn.ensemble import RandomForestClassifier\n",
    "- from sklearn.linear_model import LogisticRegression\n",
    "_____________________________________________________________\n",
    " - info, head, tail, describe \n",
    " - map(str.lower, data.columns)\n",
    " - drop\n",
    " - dropna\n",
    " - loc\n",
    " - astype\n",
    " - duplicated().sum()\n",
    " - дисбаланс классов \n",
    " - value_counts(normalize=True)\n",
    " - plot(kind='bar')\n",
    " - value_counts()\n",
    " - get_dummies(df, drop_first = True)\n",
    " _____________________________________________________________\n",
    " - train_test_split(df, test_size=0.40, random_state=12345)\n",
    " _____________________________________________________________\n",
    " - model = DecisionTreeClassifier(random_state=12345, max_depth= depth)\n",
    " - model.fit(features_train,target_train)\n",
    " - result = model.score(features_valid,target_valid)\n",
    " _____________________________________________________________\n",
    " - target_pred_constant = pd.Series(0, index=target_train.index)\n",
    " - print(accuracy_score(target_train, target_pred_constant))\n",
    " - f1_score(target_valid,predicted_valid)\n",
    "_____________________________________________________________ \n",
    " - probabilities_valid = model.predict_proba(features_valid)\n",
    " - probabilities_one_valid = probabilities_valid[:, 1]\n",
    " - print(\"AUC-ROC:\", roc_auc_score(target_valid, probabilities_one_valid))\n",
    " _____________________________________________________________\n",
    " - взвешивание классов - class_weight = 'balanced'\n",
    " - Upsampling\n",
    " - downsample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Прогноз оттока клиентов из банка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Описание работы :\n",
    "\n",
    "Из банка стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.\n",
    "\n",
    "На основании исторических данных нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет.  \n",
    "\n",
    "Необходимо постройть модель со значением *F1*-меры не меньше 0.59, дополнительно измеряя метрику *AUC-ROC*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Описание данных :\n",
    "\n",
    "* `RowNumber` — индекс строки в данных\n",
    "* `CustomerId` — уникальный идентификатор клиента\n",
    "* `Surname` — фамилия\n",
    "* `CreditScore` — кредитный рейтинг\n",
    "* `Geography` — страна проживания\n",
    "* `Gender` — пол\n",
    "* `Age` — возраст\n",
    "* `Tenure` — количество недвижимости у клиента\n",
    "* `Balance` — баланс на счёте\n",
    "* `NumOfProducts` — количество продуктов банка, используемых клиентом\n",
    "* `HasCrCard` — наличие кредитной карты\n",
    "* `IsActiveMember` — активность клиента\n",
    "* `EstimatedSalary` — предполагаемая зарплата\n",
    "* `Exited` — факт ухода клиента"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### План работы над проектом :\n",
    "\n",
    "   1. [Подготовка данных:](#Step_1)\n",
    "       * [Обзор и загрузка данных](#Step_1_1)\n",
    "       * [Приведение названий столбцов к нижнему регистру](#Step_1_2)\n",
    "       * [Обработка пропусков](#Step_1_3)\n",
    "       * [Преобразование данных в нужные типы](#Step_1_4)\n",
    "       * [Обработка дубликатов](#Step_1_5)\n",
    "       * [Вывод](#Step_1_6)\n",
    "   2. [Исследование задачи](#Step_2)\n",
    "       * [Исследование баланса классов](#Step_2_1)\n",
    "       * [Изучение модели без учёта дисбаланса](#Step_2_2)\n",
    "       * [Вывод](#Step_2_3)\n",
    "   3. [Борьба с дисбалансом](#Step_3)\n",
    "       * [Исследование баланса классов](#Step_3_1)\n",
    "       * [Вывод](#Step_3_2)\n",
    "   4. [Тестирование модели](#Step_4)\n",
    "   5. [Общий вывод](#Step_5)\n",
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Подготовка данных <a id=\"Step_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Обзор и загрузка данных <a id=\"Step_1_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим необходимые для работы библиотеки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# для разделения данных на выборки\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# для использования алгоритма классификации \"решающее дерево\"\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# для определения количества правильных ответов\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# для вычисления значения F1-меры\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# для расчёта метрики AUC-ROC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# для перемешивания объектов при использовании техники борьбы с дисбалансом upsampling\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# для использования алгоритма классификации \"случайный лес\"\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# для использования алгоритма логистической регрессии\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Откроем файл с данными и изучим общую информацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/datasets/Churn.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9995</td>\n",
       "      <td>9996</td>\n",
       "      <td>15606229</td>\n",
       "      <td>Obijiaku</td>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9996</td>\n",
       "      <td>9997</td>\n",
       "      <td>15569892</td>\n",
       "      <td>Johnstone</td>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10.0</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9997</td>\n",
       "      <td>9998</td>\n",
       "      <td>15584532</td>\n",
       "      <td>Liu</td>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9998</td>\n",
       "      <td>9999</td>\n",
       "      <td>15682355</td>\n",
       "      <td>Sabbatini</td>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3.0</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9999</td>\n",
       "      <td>10000</td>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
       "0             1    15634602   Hargrave          619    France  Female   42   \n",
       "1             2    15647311       Hill          608     Spain  Female   41   \n",
       "2             3    15619304       Onio          502    France  Female   42   \n",
       "3             4    15701354       Boni          699    France  Female   39   \n",
       "4             5    15737888   Mitchell          850     Spain  Female   43   \n",
       "...         ...         ...        ...          ...       ...     ...  ...   \n",
       "9995       9996    15606229   Obijiaku          771    France    Male   39   \n",
       "9996       9997    15569892  Johnstone          516    France    Male   35   \n",
       "9997       9998    15584532        Liu          709    France  Female   36   \n",
       "9998       9999    15682355  Sabbatini          772   Germany    Male   42   \n",
       "9999      10000    15628319     Walker          792    France  Female   28   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0        2.0       0.00              1          1               1   \n",
       "1        1.0   83807.86              1          0               1   \n",
       "2        8.0  159660.80              3          1               0   \n",
       "3        1.0       0.00              2          0               0   \n",
       "4        2.0  125510.82              1          1               1   \n",
       "...      ...        ...            ...        ...             ...   \n",
       "9995     5.0       0.00              2          1               0   \n",
       "9996    10.0   57369.61              1          1               1   \n",
       "9997     7.0       0.00              1          0               1   \n",
       "9998     3.0   75075.31              2          1               0   \n",
       "9999     NaN  130142.79              1          1               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "0           101348.88       1  \n",
       "1           112542.58       0  \n",
       "2           113931.57       1  \n",
       "3            93826.63       0  \n",
       "4            79084.10       0  \n",
       "...               ...     ...  \n",
       "9995         96270.64       0  \n",
       "9996        101699.77       0  \n",
       "9997         42085.58       1  \n",
       "9998         92888.52       1  \n",
       "9999         38190.78       0  \n",
       "\n",
       "[10000 rows x 14 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      "RowNumber          10000 non-null int64\n",
      "CustomerId         10000 non-null int64\n",
      "Surname            10000 non-null object\n",
      "CreditScore        10000 non-null int64\n",
      "Geography          10000 non-null object\n",
      "Gender             10000 non-null object\n",
      "Age                10000 non-null int64\n",
      "Tenure             9091 non-null float64\n",
      "Balance            10000 non-null float64\n",
      "NumOfProducts      10000 non-null int64\n",
      "HasCrCard          10000 non-null int64\n",
      "IsActiveMember     10000 non-null int64\n",
      "EstimatedSalary    10000 non-null float64\n",
      "Exited             10000 non-null int64\n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>9091.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569094e+07</td>\n",
       "      <td>650.528800</td>\n",
       "      <td>38.921800</td>\n",
       "      <td>4.997690</td>\n",
       "      <td>76485.889288</td>\n",
       "      <td>1.530200</td>\n",
       "      <td>0.70550</td>\n",
       "      <td>0.515100</td>\n",
       "      <td>100090.239881</td>\n",
       "      <td>0.203700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>2886.89568</td>\n",
       "      <td>7.193619e+04</td>\n",
       "      <td>96.653299</td>\n",
       "      <td>10.487806</td>\n",
       "      <td>2.894723</td>\n",
       "      <td>62397.405202</td>\n",
       "      <td>0.581654</td>\n",
       "      <td>0.45584</td>\n",
       "      <td>0.499797</td>\n",
       "      <td>57510.492818</td>\n",
       "      <td>0.402769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.556570e+07</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.580000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>2500.75000</td>\n",
       "      <td>1.562853e+07</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51002.110000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569074e+07</td>\n",
       "      <td>652.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>97198.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100193.915000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>7500.25000</td>\n",
       "      <td>1.575323e+07</td>\n",
       "      <td>718.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>127644.240000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>149388.247500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.581569e+07</td>\n",
       "      <td>850.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>250898.090000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>199992.480000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         RowNumber    CustomerId   CreditScore           Age       Tenure  \\\n",
       "count  10000.00000  1.000000e+04  10000.000000  10000.000000  9091.000000   \n",
       "mean    5000.50000  1.569094e+07    650.528800     38.921800     4.997690   \n",
       "std     2886.89568  7.193619e+04     96.653299     10.487806     2.894723   \n",
       "min        1.00000  1.556570e+07    350.000000     18.000000     0.000000   \n",
       "25%     2500.75000  1.562853e+07    584.000000     32.000000     2.000000   \n",
       "50%     5000.50000  1.569074e+07    652.000000     37.000000     5.000000   \n",
       "75%     7500.25000  1.575323e+07    718.000000     44.000000     7.000000   \n",
       "max    10000.00000  1.581569e+07    850.000000     92.000000    10.000000   \n",
       "\n",
       "             Balance  NumOfProducts    HasCrCard  IsActiveMember  \\\n",
       "count   10000.000000   10000.000000  10000.00000    10000.000000   \n",
       "mean    76485.889288       1.530200      0.70550        0.515100   \n",
       "std     62397.405202       0.581654      0.45584        0.499797   \n",
       "min         0.000000       1.000000      0.00000        0.000000   \n",
       "25%         0.000000       1.000000      0.00000        0.000000   \n",
       "50%     97198.540000       1.000000      1.00000        1.000000   \n",
       "75%    127644.240000       2.000000      1.00000        1.000000   \n",
       "max    250898.090000       4.000000      1.00000        1.000000   \n",
       "\n",
       "       EstimatedSalary        Exited  \n",
       "count     10000.000000  10000.000000  \n",
       "mean     100090.239881      0.203700  \n",
       "std       57510.492818      0.402769  \n",
       "min          11.580000      0.000000  \n",
       "25%       51002.110000      0.000000  \n",
       "50%      100193.915000      0.000000  \n",
       "75%      149388.247500      0.000000  \n",
       "max      199992.480000      1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(df)\n",
    "df.info()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим более подробно каждый столбец фрейма `df`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `RowNumber` — индекс строки в данных. Столбец можно будет удалить, так как он полностью дублирует функцию индекса.\n",
    "* `CustomerId` — уникальный идентификатор клиента. Без аномалий.\n",
    "* `Surname` — фамилия. Бесполезный для нас признак. Его функцию уже выполняет уникальный id каждого клиента. \n",
    "* `CreditScore` — кредитный рейтинг. Значения все на месте, тип данных адекватный. \n",
    "* `Geography`, `Gender`, `Age`  — страна проживания, пол, возраст соотвественно. Пропуски отсуствуют.\n",
    "* `Tenure` — количество недвижимости у клиента. Почти 10% пропуск и дробный тип данных, который тут нам совершенно ни к чему.\n",
    "* `Balance` — баланс на счёте. Данные все на месте, но от копеек можно будет избавиться.\n",
    "* `NumOfProducts`, `HasCrCard`, `IsActiveMember` — количество продуктов банка, используемых клиентом, наличие кредитной карты и активность клиента. Без замечений.\n",
    "* `EstimatedSalary` — предполагаемая зарплата. Пропусков нет, данные округлим до целых чисел.\n",
    "* `Exited` — факт ухода клиента. Наш целевой признак. Все данные на месте."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Приведение названий столбцов к нижнему регистру <a id=\"Step_1_2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = map(str.lower, df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь же удалим признаки, идентифицированные нами, как явно лишние."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['rownumber', 'surname'], axis = 'columns', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Обработка пропусков <a id=\"Step_1_3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Единственным признаком, где у нас существуют пропуски является `tenure`. Хороший вопрос, что является большей потерей для построения модели: искажение 10% данных одного признака, при заполнении существующих пропусков тем или иным образом, или удаления 10% всех объектов, которые соответствуют имеющимся пропускам, но чистые данные на выходе. \n",
    "\n",
    "Руководствуясь принципом бритвы Оккама, я предпочту выбрать кратчайший путь: удалим все объекты с пропусками. \n",
    "В случае успешного решения поставленной задачи и преодоления минимально необходимого порога `F1-меры`, будем считать данное решение правомерным.\n",
    "\n",
    "Также, относительно природы данных пропусков можно предположить, что здесь, как всегда, может быть заложена ошибка автоматики или/либо человеческий фактор при операциях с данными от начала получения данных банков до передачи в качестве исходной информации нам, для решения поставленной задачи. Ещё одна версия может заключаться в том, что у банк просто нет информации о владении недвижимостью теми или иными клиентами, так как клиенты, в свою очередь, просто отказались её сообщать. Нельзя исключить и какую-то комбинацию описанных выше признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset = ['tenure'], inplace = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Преобразование данных в нужные типы  <a id=\"Step_1_4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изменим тип данных на `int` в столбцах `tenure`, `balance`, `estimatedsalary`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,['tenure', 'balance', 'estimatedsalary']] = (df\n",
    "                                                      .loc[:,['tenure'\n",
    "                                                              , 'balance'\n",
    "                                                              , 'estimatedsalary']]\n",
    "                                                      .astype('int'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Обработка дубликатов  <a id=\"Step_1_5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим фрейм на наличие полных дубликатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df.duplicated().sum()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полные дубликаты отсутствуют. На всякий случай проверим ещё дубликаты уникальных `id` клиентов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df['customerid'].duplicated().sum()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также ничего."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Вывод  <a id=\"Step_1_6\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   1. *Данные и необходимые для работы библиотеки успешно загружены.*\n",
    "   2. *Проведён первичный анализ, определены и выполнены необходимые действия для последующей корректной подготовки и предобработки имеющейся информации:*\n",
    "    * *Регистр заголовков изменён на нижний;*\n",
    "    * *Для столбцов `tenure`, `balance`, `estimatedsalary` изменён тип данных;*\n",
    "    * *Объекты, имеющий пропуск в столбце `tenure`, удалены; *\n",
    "    * *Проверка на наличие дубликатов произведена. Дубликатов не обнаружено;*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Исследование задачи <a id=\"Step_2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Исследование баланса классов  <a id=\"Step_2_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исследуем баланс классов нашего целевого признака `Exited`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.796062\n",
      "1    0.203938\n",
      "Name: exited, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "class_frequency = df['exited'].value_counts(normalize=True)\n",
    "print(class_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f5e603a4cd0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_frequency.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Явный перекос в сторону тех, кто остался, почти 80% на 20%, что в целом и ожидаемо."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Изучение модели без учёта дисбаланса  <a id=\"Step_2_2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим модель без учёта дисбаланса.\n",
    "\n",
    "Для корректной работы модели нам необходимо признаки категориальные перевести в численные. Нас интересуют признаки `geography` и `gender`. Посмотрим какие значения они содержат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "France     4550\n",
       "Germany    2293\n",
       "Spain      2248\n",
       "Name: geography, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['geography'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Male      4974\n",
       "Female    4117\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исходя из небольшого количества вида значений в каждом из признаков, воспользуемся техникой прямого кодирования (One-Hot Encoding, OHE)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы не попасть в так называемую дамми-ловушку при добавлении новых столбцов после применения техники OHE, удалим в каждом из случаев первый столбец из добавленных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, drop_first = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее, разделим исходные данные на обучающую, валидационную и тестовую выборки в пропорции 60% / 20% / 20% соответственно.\n",
    "\n",
    "Сначала разобьём данные в пропорции 60 / 40, сформировав тем самым обучающий набор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_other = train_test_split(df, test_size=0.40, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь, оставшиеся 40% данных, снова разделим пополам, получив тем самым валидационную и тестовую выборки в пропорции 20% каждая от исходных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid, df_test = train_test_split(df_other, test_size=0.50, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед тем, как приступить непосредственно к исследованию моделей, создадим переменные для хранения признаков и целевого признака каждой из выборок."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучающая выборка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = df_train.drop(['exited'], axis=1)\n",
    "target_train = df_train['exited']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Валидационная выборка. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_valid = df_valid.drop(['exited'], axis=1)\n",
    "target_valid = df_valid['exited']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тестовая выборка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = df_test.drop(['exited'], axis=1)\n",
    "target_test = df_test['exited']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для анализа модели, построенной без учёта дисбаланса классов, выберем алгоритм классификациий решающего дерева `DecisionTreeClassifier`. Определим лучшее значение `accuracy`, изменяя гиперпараметр `max_depth`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best_depth: 6\n",
      "Accuracy: 0.8586358635863587\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "best_result = 0\n",
    "\n",
    "for depth in range(1,30): \n",
    "    \n",
    "    model = DecisionTreeClassifier(random_state=12345, max_depth= depth)\n",
    "    model.fit(features_train,target_train)\n",
    "    result = model.score(features_valid,target_valid)\n",
    "    \n",
    "    if result > best_result:\n",
    "        best_model = model \n",
    "        best_result = result\n",
    "        best_depth = depth\n",
    "\n",
    "print(\"Best_depth:\", best_depth)     \n",
    "print(\"Accuracy:\", best_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проанализируем частоты классов в результатах предсказаний решающего дерева."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.887789\n",
      "1    0.112211\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f5e6099cd90>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(random_state=12345, max_depth = 6)\n",
    "model.fit(features_train,target_train)\n",
    "predicted_valid = pd.Series(model.predict(features_valid))\n",
    "class_frequency = predicted_valid.value_counts(normalize=True)\n",
    "\n",
    "print(class_frequency)\n",
    "\n",
    "class_frequency.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат сместися почти на 9% относительно баланса классов в исходных данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим теперь какой результат нам даст константная модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7935460212687936\n"
     ]
    }
   ],
   "source": [
    "target_pred_constant = pd.Series(0, index=target_train.index)\n",
    "\n",
    "print(accuracy_score(target_train, target_pred_constant))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разница с решающим деревом около 6% в пользу последнего."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тем не менее метрика `accuracy` в данном случае не является для нас показательной. Для дальнейшего анализа качества построенной модели, будем пользоваться метриками `F1-мерой` и `AUC-ROC`. \n",
    "\n",
    "Посчитаем `F1-меру` и `AUC-ROC` для нашей несбалансированной модели при использовании алгоритма решающего дерева."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score: 0.557659208261618\n"
     ]
    }
   ],
   "source": [
    "print(\"F1_score:\", f1_score(target_valid,predicted_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC: 0.8425699070605623\n"
     ]
    }
   ],
   "source": [
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "print(\"AUC-ROC:\", roc_auc_score(target_valid, probabilities_one_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Вывод <a id=\"Step_2_3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сильный дисбаланс классов, достаточно далёкий от соотношения 1:1, значительно затрудняет обучение модели, но тем не менее модель, построенная на алгоритме решающего дерева, выдаёт не идеальные, но и не самые плохие результаты: \n",
    "   * `acccuracy` = 0.8586358635863587\n",
    "   * `F1_score` = 0.557659208261618\n",
    "   * `AUC-ROC` = 0.8425699070605623\n",
    "\n",
    "Метрика `accuracy` не является для нас показательной, но `F1_score` и `AUC-ROC` будем считать отправными точками, взятыми для несбалансированной модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Борьба с дисбалансом <a id=\"Step_3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Применение способов борьбы с дисбалансом  <a id=\"Step_3_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для борьбы с дисбалансом можно воспользоваться следующими техниками: взвешивание классов, upsampling и downsampling. \n",
    "\n",
    "Посчитаем метрики `F1-меру` и `AUC-ROC`, используя каждую из техник, для решающего дерева, случайного леса и логистической регрессии. Сравним результаты между собой и с несбалансированной моделью и выберем лучший вариант из трёх."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Решающее дерево"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Взвешивание классов*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Установим аргумент `class_weight = 'balanced'` для модели решающего дерева. Также выберем при этом оптимальный гиперпараметр `max_depth`, определяющий размер решающего дерева. Рассчитаем метрики `F1-меру` и `AUC-ROC`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best_depth =  5\n",
      "F1-score =  0.5711252653927813\n",
      "AUC-ROC =  0.8351765370717726\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "best_result_f1 = 0\n",
    "\n",
    "for depth in range(1,30): \n",
    "    \n",
    "    model = DecisionTreeClassifier(random_state=12345\n",
    "                                   , max_depth= depth\n",
    "                                   , class_weight = 'balanced' )\n",
    "    model.fit(features_train,target_train)\n",
    "    predictions_valid = model.predict(features_valid)\n",
    "    result_f1 = f1_score(target_valid, predictions_valid)\n",
    "    \n",
    "    probabilities_valid = model.predict_proba(features_valid)\n",
    "    probabilities_one_valid = probabilities_valid[:, 1]\n",
    "    result_roc_auc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "    \n",
    "    if result_f1 > best_result_f1:\n",
    "        best_model = model \n",
    "        best_depth = depth\n",
    "        best_result_f1 = result_f1\n",
    "        best_result_roc_auc = result_roc_auc\n",
    "\n",
    "print(\"Best_depth = \", best_depth)    \n",
    "print(\"F1-score = \", best_result_f1)\n",
    "print(\"AUC-ROC = \", best_result_roc_auc) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Размер дерева решений уменьшился, среднее гармоническое полноты и точности подросло, , а вот метрика `AUC-ROC` у нас немного изменилась в меньшую сторону."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Upsampling*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для реализации данной техники напишем функцию `upsample`, которая позволит нам увеличить количество объектов редкого класса и тем самым сбалансировать нашу модель.\n",
    "\n",
    "На данный момент соотношение находится в пропорции 80% на 20%. Следовательно количество объектов, относящихся к классу 1 целевого признака, увеличим в 4 раза, за что в нашей функции будет отвечать переменная `repeat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(features, target, repeat):\n",
    "    \n",
    "    # разделим обучающую выборку на отрицательные и положительные объекты\n",
    "    \n",
    "    # features_zeros — признаки объектов с ответом «0»\n",
    "    features_zeros = features[target == 0]\n",
    "    \n",
    "    # features_ones — признаки объектов с ответом «1»\n",
    "    features_ones = features[target == 1]\n",
    "    \n",
    "    # target_zeros — целевой признак объектов, у которых ответы только «0»\n",
    "    target_zeros = target[target == 0]\n",
    "    \n",
    "    # target_ones — целевой признак объектов, у которых ответы только «1»\n",
    "    target_ones = target[target == 1]\n",
    "    \n",
    "    # Продублируем объекты положительного класса и объединим их с объектами отрицательного класса.\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "    \n",
    "    # Перемешаем данные с помощью функции shuffle()\n",
    "    features_upsampled, target_upsampled = shuffle(\n",
    "        features_upsampled, target_upsampled, random_state=12345)\n",
    "    \n",
    "    return features_upsampled, target_upsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим написанную функцию к тренировочным данным, обучим на них решающее дерево и посмотрим результат для `F1 - меры` и `AUC-ROC`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_upsampled, target_upsampled = upsample(features_train, target_train, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best_depth =  5\n",
      "F1-score =  0.5711252653927813\n",
      "AUC-ROC =  0.8351765370717726\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "best_depth = 0\n",
    "best_result_f1 = 0\n",
    "best_result_roc_auc = 0\n",
    "\n",
    "for depth in range(1,30): \n",
    "    \n",
    "    model = DecisionTreeClassifier(random_state=12345\n",
    "                                   , max_depth= depth)\n",
    "    model.fit(features_upsampled,target_upsampled)\n",
    "    predictions_valid = model.predict(features_valid)\n",
    "    result_f1 = f1_score(target_valid, predictions_valid)\n",
    "    \n",
    "    probabilities_valid = model.predict_proba(features_valid)\n",
    "    probabilities_one_valid = probabilities_valid[:, 1]\n",
    "    result_roc_auc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "    \n",
    "    if result_f1 > best_result_f1:\n",
    "        best_model = model \n",
    "        best_depth = depth\n",
    "        best_result_f1 = result_f1\n",
    "        best_result_roc_auc = result_roc_auc\n",
    "\n",
    "print(\"Best_depth = \", best_depth)    \n",
    "print(\"F1-score = \", best_result_f1)\n",
    "print(\"AUC-ROC = \", best_result_roc_auc) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полностью аналогичный взвешиванию классов результат. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Downsampling*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для реализации данной техники напишем функцию `downsample` по аналогии с функцией `upsample`, только в этот раз мы будем уменьшать частый класс, а не увеличивать редкий.\n",
    "\n",
    "Изначально соотношение классов 80% на 20%. Следовательно количество объектов, относящихся к классу 0 целевого признака, уменьшим в 4 раза, за что в нашей функции будет отвечать переменная `fractio`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(features, target, fraction):\n",
    "    \n",
    "    # также разделим обучающую выборку на отрицательные и положительные объекты\n",
    "    \n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "    \n",
    "    # Сократим количество объектов отрицательного класса и объединим их с объектами положительного.\n",
    "    features_downsampled = pd.concat(\n",
    "        [features_zeros.sample(frac=fraction, random_state=12345)] + [features_ones]) \n",
    "    target_downsampled = pd.concat(\n",
    "        [target_zeros.sample(frac=fraction, random_state=12345)] + [target_ones]) \n",
    "    \n",
    "    return features_downsampled, target_downsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим написанную функцию к тренировочным данным, обучим на них решающее дерево и посмотрим результат для `F1 - меры` и `AUC-ROC`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_downsampled, target_downsampled = downsample(features_train, target_train, 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best_depth =  6\n",
      "F1-score =  0.5605214152700186\n",
      "AUC-ROC =  0.8326307806434156\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "best_depth = 0\n",
    "best_result_f1 = 0\n",
    "best_result_roc_auc = 0\n",
    "\n",
    "for depth in range(1,30): \n",
    "    \n",
    "    model = DecisionTreeClassifier(random_state=12345\n",
    "                                   , max_depth= depth)\n",
    "    model.fit(features_downsampled,target_downsampled)\n",
    "    predictions_valid = model.predict(features_valid)\n",
    "    result_f1 = f1_score(target_valid, predictions_valid)\n",
    "    \n",
    "    probabilities_valid = model.predict_proba(features_valid)\n",
    "    probabilities_one_valid = probabilities_valid[:, 1]\n",
    "    result_roc_auc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "    \n",
    "    if result_f1 > best_result_f1:\n",
    "        best_model = model \n",
    "        best_depth = depth\n",
    "        best_result_f1 = result_f1\n",
    "        best_result_roc_auc = result_roc_auc\n",
    "\n",
    "print(\"Best_depth = \", best_depth)    \n",
    "print(\"F1-score = \", best_result_f1)\n",
    "print(\"AUC-ROC = \", best_result_roc_auc) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В случае данной техники ухудшилась каждая из характеристик. \n",
    "\n",
    "Учитывая контекст нашей задачи и тот факт, что ни одна из техник, применённая в рамках алгоритма решающего дерева, хоть и дала лучший по сравнению с несбалансированной моделью результаты, тем не менее не позволила получить нам `F1-score` выше 0.59. Таким образом с этим видом классификатора в нашем исследовании мы прощаемся. \n",
    "\n",
    "Воспользуемся теми же техниками борьбы с дисбалансом, но на этот раз для случайного леса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Случайный лес"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Взвешивание классов*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и для решающего дерева, установим аргумент `class_weight = 'balanced'`. Также выберем при этом оптимальный гиперпараметр `n_estimators`, определяющий размер решающего дерева. Рассчитаем метрики `F1-меру` и `AUC-ROC`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best_est =  30\n",
      "F1-score =  0.5530434782608695\n",
      "AUC-ROC =  0.8582613753711411\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "best_result_f1 = 0\n",
    "\n",
    "for est in range(10, 150, 10): \n",
    "    \n",
    "    model = RandomForestClassifier(random_state=12345\n",
    "                                   , n_estimators= est\n",
    "                                   , class_weight = 'balanced')\n",
    "    model.fit(features_train,target_train)\n",
    "    predictions_valid = model.predict(features_valid)\n",
    "    result_f1 = f1_score(target_valid, predictions_valid)\n",
    "    \n",
    "    probabilities_valid = model.predict_proba(features_valid)\n",
    "    probabilities_one_valid = probabilities_valid[:, 1]\n",
    "    result_roc_auc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "    \n",
    "    if result_f1 > best_result_f1:\n",
    "        best_model = model \n",
    "        best_est = est\n",
    "        best_result_f1 = result_f1\n",
    "        best_result_roc_auc = result_roc_auc\n",
    "\n",
    "print(\"Best_est = \", best_est)    \n",
    "print(\"F1-score = \", best_result_f1)\n",
    "print(\"AUC-ROC = \", best_result_roc_auc) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`F1-score` почти как для несбалансированной модели. А вот `AUC-ROC` подросла. Посмотрим как покажут себя другие техники для данного алгоритма. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Upsampling*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best_est =  110\n",
      "F1-score =  0.6262924667651403\n",
      "AUC-ROC =  0.8652451786171186\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "best_result_f1 = 0\n",
    "\n",
    "for est in range(10, 150, 10): \n",
    "    \n",
    "    model = RandomForestClassifier(random_state=12345\n",
    "                                   , n_estimators= est)\n",
    "    model.fit(features_upsampled,target_upsampled)\n",
    "    predictions_valid = model.predict(features_valid)\n",
    "    result_f1 = f1_score(target_valid, predictions_valid)\n",
    "    \n",
    "    probabilities_valid = model.predict_proba(features_valid)\n",
    "    probabilities_one_valid = probabilities_valid[:, 1]\n",
    "    result_roc_auc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "    \n",
    "    if result_f1 > best_result_f1:\n",
    "        best_model = model \n",
    "        best_est = est\n",
    "        best_result_f1 = result_f1\n",
    "        best_result_roc_auc = result_roc_auc\n",
    "\n",
    "print(\"Best_est = \", best_est)    \n",
    "print(\"F1-score = \", best_result_f1)\n",
    "print(\"AUC-ROC = \", best_result_roc_auc) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рост обеих метрик! И лучший на данный момент результат. Посмотрим, что нам даст последняя техника downsampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Downsampling*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best_est =  40\n",
      "F1-score =  0.6020202020202021\n",
      "AUC-ROC =  0.8600459819201594\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "best_result_f1 = 0\n",
    "\n",
    "for est in range(10, 150, 10): \n",
    "    \n",
    "    model = RandomForestClassifier(random_state=12345\n",
    "                                   , n_estimators= est)\n",
    "    model.fit(features_downsampled,target_downsampled)\n",
    "    predictions_valid = model.predict(features_valid)\n",
    "    result_f1 = f1_score(target_valid, predictions_valid)\n",
    "    \n",
    "    probabilities_valid = model.predict_proba(features_valid)\n",
    "    probabilities_one_valid = probabilities_valid[:, 1]\n",
    "    result_roc_auc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "    \n",
    "    if result_f1 > best_result_f1:\n",
    "        best_model = model \n",
    "        best_est = est\n",
    "        best_result_f1 = result_f1\n",
    "        best_result_roc_auc = result_roc_auc \n",
    "\n",
    "print(\"Best_est = \", best_est)    \n",
    "print(\"F1-score = \", best_result_f1)\n",
    "print(\"AUC-ROC = \", best_result_roc_auc) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат уступает предыдущему варианту по каждой из метрик.\n",
    "\n",
    "Далее воспользуемся алгоритмом классификации: логистическая регрессия. Оценим, как для него будут меняться значения наших ключевых метрик `F1-score` и `AUC-ROC` в зависимости от применённой техники борьбы с дисбалансом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Взвешивание классов*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Установим аргумент `class_weight = 'balanced'` и рассмотрим изменения для нескольких гиперпараметров: \n",
    " - `solver` - алгоритм использующийся для решения проблем оптимизации; \n",
    " - `C` - параметр регуляризации;\n",
    " - `tol` - указывает алгоритму оптимизации, когда следует остановиться.\n",
    " \n",
    "Ключевыми метриками для нас будут являться всё те же `F1-меру` и `AUC-ROC`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best_solver =  liblinear\n",
      "Best_C =  0.30000000000000004\n",
      "Best_tol =  6.000000000000001e-05\n",
      "F1-score =  0.5173745173745175\n",
      "AUC-ROC =  0.7687889893733537\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "best_result_f1 = 0\n",
    "best_result_roc_auc = 0\n",
    "solver_list = ['lbfgs', 'liblinear']\n",
    "\n",
    "for solver in solver_list:\n",
    "    for c in np.arange(0.1, 1.0, 0.1):\n",
    "        for tol in np.arange(0.00002, 0.00042, 0.00002):\n",
    "\n",
    "            model = LogisticRegression(random_state=12345\n",
    "                               , C = c\n",
    "                               , tol = tol\n",
    "                               , solver = solver\n",
    "                               , class_weight = 'balanced')\n",
    "    \n",
    "            model.fit(features_train,target_train)\n",
    "            predictions_valid = model.predict(features_valid)\n",
    "            result_f1 = f1_score(target_valid, predictions_valid)\n",
    "    \n",
    "            probabilities_valid = model.predict_proba(features_valid)\n",
    "            probabilities_one_valid = probabilities_valid[:, 1]\n",
    "            result_roc_auc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "    \n",
    "            if result_f1 > best_result_f1:\n",
    "                best_model = model \n",
    "                best_solver = solver\n",
    "                best_c = c\n",
    "                best_tol = tol\n",
    "                best_result_f1 = result_f1\n",
    "                best_result_roc_auc = result_roc_auc \n",
    "\n",
    "print(\"Best_solver = \", best_solver)            \n",
    "print(\"Best_C = \", best_c)\n",
    "print(\"Best_tol = \", best_tol)\n",
    "print(\"F1-score = \", best_result_f1)\n",
    "print(\"AUC-ROC = \", best_result_roc_auc) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты, скажем прямо, так себе. Посмотрим какой результат дадут остальные техники борьбы с дисбалансом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Upsamplimg*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best_solver =  liblinear\n",
      "Best_C =  0.5\n",
      "Best_tol =  4e-05\n",
      "F1-score =  0.516441005802708\n",
      "AUC-ROC =  0.7670954999199273\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "best_result_f1 = 0\n",
    "best_result_roc_auc = 0\n",
    "solver_list = ['lbfgs', 'liblinear']\n",
    "\n",
    "for solver in solver_list:\n",
    "    for c in np.arange(0.1, 1.0, 0.1):\n",
    "        for tol in np.arange(0.00002, 0.00042, 0.00002):\n",
    "\n",
    "            model = LogisticRegression(random_state=12345\n",
    "                               , C = c\n",
    "                               , tol = tol\n",
    "                               , solver = solver\n",
    "                               , class_weight = 'balanced')\n",
    "    \n",
    "            model.fit(features_upsampled,target_upsampled)\n",
    "            predictions_valid = model.predict(features_valid)\n",
    "            result_f1 = f1_score(target_valid, predictions_valid)\n",
    "    \n",
    "            probabilities_valid = model.predict_proba(features_valid)\n",
    "            probabilities_one_valid = probabilities_valid[:, 1]\n",
    "            result_roc_auc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "    \n",
    "            if result_f1 > best_result_f1:\n",
    "                best_model = model \n",
    "                best_solver = solver\n",
    "                best_c = c\n",
    "                best_tol = tol\n",
    "                best_result_f1 = result_f1\n",
    "                best_result_roc_auc = result_roc_auc \n",
    "\n",
    "print(\"Best_solver = \", best_solver)            \n",
    "print(\"Best_C = \", best_c)\n",
    "print(\"Best_tol = \", best_tol)\n",
    "print(\"F1-score = \", best_result_f1)\n",
    "print(\"AUC-ROC = \", best_result_roc_auc) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат даже несколько хуже, чем у взвешивания классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Downsampling*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best_solver =  liblinear\n",
      "Best_C =  0.30000000000000004\n",
      "Best_tol =  2e-05\n",
      "F1-score =  0.5085066162570888\n",
      "AUC-ROC =  0.7661014952407423\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "best_result_f1 = 0\n",
    "best_result_roc_auc = 0\n",
    "solver_list = ['lbfgs', 'liblinear']\n",
    "\n",
    "for solver in solver_list:\n",
    "    for c in np.arange(0.1, 1.0, 0.1):\n",
    "        for tol in np.arange(0.00002, 0.00042, 0.00002):\n",
    "\n",
    "            model = LogisticRegression(random_state=12345\n",
    "                               , C = c\n",
    "                               , tol = tol\n",
    "                               , solver = solver\n",
    "                               , class_weight = 'balanced')\n",
    "    \n",
    "            model.fit(features_downsampled,target_downsampled)\n",
    "            predictions_valid = model.predict(features_valid)\n",
    "            result_f1 = f1_score(target_valid, predictions_valid)\n",
    "    \n",
    "            probabilities_valid = model.predict_proba(features_valid)\n",
    "            probabilities_one_valid = probabilities_valid[:, 1]\n",
    "            result_roc_auc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "    \n",
    "            if result_f1 > best_result_f1:\n",
    "                best_model = model \n",
    "                best_solver = solver\n",
    "                best_c = c\n",
    "                best_tol = tol\n",
    "                best_result_f1 = result_f1\n",
    "                best_result_roc_auc = result_roc_auc \n",
    "\n",
    "print(\"Best_solver = \", best_solver)            \n",
    "print(\"Best_C = \", best_c)\n",
    "print(\"Best_tol = \", best_tol)\n",
    "print(\"F1-score = \", best_result_f1)\n",
    "print(\"AUC-ROC = \", best_result_roc_auc) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ещё более удручающие результаты, чем для 2-х предыдущих техник. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Вывод  <a id=\"Step_3_2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак. Воспользовавшись тремя техниками борьбы с дисбалансом (взвшивание классов, upsampling, downsampling) для трёх алгоритмов классификации (решающее дерево, случайный лес, логистическая регрессия), мы получили лучший результат для случайного леса, к которому применили технику upsampling, получив на выходе следующие значения ключевых метрик: \n",
    "* `F1-score` =  0.6262924667651403\n",
    "* `AUC-ROC` =  0.8652451786171186"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Тестирование модели <a id=\"Step_4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведём финальное тестирование нашей лучшей модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score =  0.6006191950464397\n",
      "AUC-ROC =  0.8511648307288634\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=12345, n_estimators= 130)\n",
    "model.fit(features_upsampled,target_upsampled)\n",
    "predictions_test = model.predict(features_test)\n",
    "result_f1 = f1_score(target_test, predictions_test)\n",
    "    \n",
    "probabilities_test = model.predict_proba(features_test)\n",
    "probabilities_one_test = probabilities_test[:, 1]\n",
    "\n",
    "result_roc_auc = roc_auc_score(target_test, probabilities_one_test)\n",
    " \n",
    "print(\"F1-score = \", result_f1)\n",
    "print(\"AUC-ROC = \", result_roc_auc) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ключевые метрики несколько ниже, чем на валидационной выборке, но, тем не менее, условие успешного выполнения проекта выполняется: `F1-score` > 0.59."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Общий вывод <a id=\"Step_5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На основании предоставленных банком исторических данных поведения клиетов, нами было проведенно исследование на предмет построения модели, способной предсказать, какой клиет в ближайшем будущем скорее всего уйдёт, а какой останется. Для банка более чем актуальный вопрос, так как (и это оговорено в условии) удержать клиента дешевле, чем привлечь нового. \n",
    "\n",
    "Данные были загружены, изучены и прошли необходимую для дальнейшей работы предобработку. \n",
    "\n",
    "Основной проблемой в предоставленных данных являлся явный дисбаланс классов (80% - 0, 20% - 1), что в свою очередь существенно затрудняет обучение модели. \n",
    "\n",
    "Для борьбы с дисбалансом мы использовали три техники: взвешивание классов, upsampling и downsampling. Эти техники были использованы для построения моделей в рамках трёх алгоритмов классификации: решающего дерева, случайного леса и логистической регрессии. \n",
    "\n",
    "Результатом исследования, применения техник и алгоритмов, стала модель (лучшая из полученных) на основе алгоритма решающего дерева, где для борьбы с дисбалансом была применена техника upsampling. На тестовой выборке были получены следующие значения ключевых метрик: \n",
    "* `F1-score` =  0.6006191950464397\n",
    "* `AUC-ROC` =  0.8511648307288634\n",
    "\n",
    "Таким образом, мы получили модель, которая способна достаточно точно (`F1-score` > 0.59) выявлять клиентов, которые скоро могут закончить взаимотношения с данным банком. Это в свою очередь, позволит банку своевременно провести с этими клиентами дополнительную работу для того, чтобы подобного всё таки не допустить."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1119,
    "start_time": "2022-03-11T17:48:59.247Z"
   },
   {
    "duration": 41,
    "start_time": "2022-03-11T17:49:00.369Z"
   },
   {
    "duration": 78,
    "start_time": "2022-03-11T17:49:00.413Z"
   },
   {
    "duration": 3,
    "start_time": "2022-03-11T17:49:00.493Z"
   },
   {
    "duration": 16,
    "start_time": "2022-03-11T17:49:00.498Z"
   },
   {
    "duration": 16,
    "start_time": "2022-03-11T17:49:00.515Z"
   },
   {
    "duration": 20,
    "start_time": "2022-03-11T17:49:00.532Z"
   },
   {
    "duration": 22,
    "start_time": "2022-03-11T17:49:00.555Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-11T17:49:00.580Z"
   },
   {
    "duration": 15,
    "start_time": "2022-03-11T17:49:00.586Z"
   },
   {
    "duration": 253,
    "start_time": "2022-03-11T17:49:00.603Z"
   },
   {
    "duration": 7,
    "start_time": "2022-03-11T17:49:00.858Z"
   },
   {
    "duration": 17,
    "start_time": "2022-03-11T17:49:00.867Z"
   },
   {
    "duration": 24,
    "start_time": "2022-03-11T17:49:00.886Z"
   },
   {
    "duration": 10,
    "start_time": "2022-03-11T17:49:00.912Z"
   },
   {
    "duration": 31,
    "start_time": "2022-03-11T17:49:00.923Z"
   },
   {
    "duration": 13,
    "start_time": "2022-03-11T17:49:00.956Z"
   },
   {
    "duration": 13,
    "start_time": "2022-03-11T17:49:00.971Z"
   },
   {
    "duration": 10,
    "start_time": "2022-03-11T17:49:00.985Z"
   },
   {
    "duration": 834,
    "start_time": "2022-03-11T17:49:00.997Z"
   },
   {
    "duration": 174,
    "start_time": "2022-03-11T17:49:01.833Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-11T17:49:02.009Z"
   },
   {
    "duration": 8,
    "start_time": "2022-03-11T17:49:02.018Z"
   },
   {
    "duration": 22,
    "start_time": "2022-03-11T17:49:02.028Z"
   },
   {
    "duration": 959,
    "start_time": "2022-03-11T17:49:02.052Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-11T17:49:03.013Z"
   },
   {
    "duration": 17,
    "start_time": "2022-03-11T17:49:03.019Z"
   },
   {
    "duration": 1195,
    "start_time": "2022-03-11T17:49:03.038Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-11T17:49:04.235Z"
   },
   {
    "duration": 14,
    "start_time": "2022-03-11T17:49:04.241Z"
   },
   {
    "duration": 457,
    "start_time": "2022-03-11T17:49:04.257Z"
   },
   {
    "duration": 8189,
    "start_time": "2022-03-11T17:49:04.716Z"
   },
   {
    "duration": 11644,
    "start_time": "2022-03-11T17:49:12.907Z"
   },
   {
    "duration": 4184,
    "start_time": "2022-03-11T17:49:24.553Z"
   },
   {
    "duration": 84640,
    "start_time": "2022-03-11T17:49:28.739Z"
   },
   {
    "duration": 93903,
    "start_time": "2022-03-11T17:50:53.381Z"
   },
   {
    "duration": 64209,
    "start_time": "2022-03-11T17:52:27.376Z"
   },
   {
    "duration": 1978,
    "start_time": "2022-03-11T17:53:31.588Z"
   },
   {
    "duration": 1683,
    "start_time": "2022-05-09T06:44:57.422Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
